{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üìò Linear Regression Summary\n",
        "\n",
        "Linear Regression is a supervised learning algorithm used to find the best-fitting straight line that represents the relationship between input X and output y.\n",
        "\n",
        "The model assumes a linear relationship:\n",
        "y = wX + b\n",
        "where:\n",
        "\n",
        "y ‚Üí predicted value\n",
        "\n",
        "w ‚Üí weight (slope)\n",
        "\n",
        "b ‚Üí bias (intercept)\n",
        "\n",
        "1Ô∏è‚É£ Loss Function (Mean Squared Error):\n",
        "To measure how well the model fits the data, we use:\n",
        "L = (1 / n) Œ£ (y - (wX + b))¬≤\n",
        "The goal is to minimize this loss.\n",
        "\n",
        "2Ô∏è‚É£ Gradient Descent (Optimization):\n",
        "We iteratively update the parameters w and b to reduce the loss.\n",
        "The gradients (partial derivatives) are:\n",
        "‚àÇL/‚àÇw = (2 / n) Œ£ X ( (wX + b) - y )\n",
        ",\n",
        "‚àÇL/‚àÇb = (2 / n) Œ£ ( (wX + b) - y )\n",
        "\n",
        "3Ô∏è‚É£ Parameter Update Rules:\n",
        "At each iteration:\n",
        "w = w - Œ± * (‚àÇL/‚àÇw) ,\n",
        "b = b - Œ± * (‚àÇL/‚àÇb)\n",
        "where Œ± is the learning rate (controls step size).\n",
        "\n",
        "‚úÖ Final Goal:\n",
        "After several iterations, the model learns the optimal values of w and b that minimize the loss and best fit the data."
      ],
      "metadata": {
        "id": "LBb7Hi76pIfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self, lr=0.01, n_iters=1000):\n",
        "        # Initialize hyperparameters\n",
        "        self.lr = lr                # Learning rate\n",
        "        self.n_iters = n_iters      # Number of iterations\n",
        "        self.weights = None         # Model weights (coefficients)\n",
        "        self.bias = None            # Model bias (intercept)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Initialize parameters\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient Descent loop\n",
        "        for _ in range(self.n_iters):\n",
        "            # Predicted values\n",
        "            y_pred = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "            # Compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Return predicted values\n",
        "        return np.dot(X, self.weights) + self.bias\n"
      ],
      "metadata": {
        "id": "esCIBvhOlR76"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò Code Explanation\n",
        "\n",
        "Step 1 ‚Äî Create the data\n",
        "We create simple training data where the true relationship is y = 2x.\n",
        "X represents the input values, and y represents the target (output) values.\n",
        "\n",
        "Step 2 ‚Äî Create and train the model\n",
        "We create a LinearRegression model with:\n",
        "\n",
        "Learning rate (lr) = 0.01 ‚Üí controls how fast the model learns\n",
        "\n",
        "Iterations (n_iters) = 1000 ‚Üí number of updates to improve accuracy\n",
        "\n",
        "The model is trained using the fit() function, which applies Gradient Descent to find the best line that fits the data by adjusting the weight (w) and bias (b) values to minimize the prediction error.\n",
        "\n",
        "Step 3 ‚Äî Make predictions\n",
        "After training, we use the predict() function to test the model with new inputs [6, 7, 8].\n",
        "The model applies the learned linear equation:\n",
        "y = w √ó X + b\n",
        "to generate predicted outputs."
      ],
      "metadata": {
        "id": "GP2SeAGCqQom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 6, 8, 10])  # True relation: y = 2x\n",
        "\n",
        "# Create and train model\n",
        "model = LinearRegression(lr=0.01, n_iters=1000)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(np.array([[6], [7], [8]]))\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIz8A5u8mlbH",
        "outputId": "913540a0-f157-4fdf-97ca-b14c1679c955"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11.93728249 13.91103737 15.88479225]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmFWhBOgnEOW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}